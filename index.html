<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ashim Dahal</title>

    <meta name="author" content="Ashim Dahal">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Ashim Dahal
                </p>
                <p>I'm an Undergraduate Research Assistant at <a href="https://usm.edu">The University of Southern Mississippi</a> in Mississippi, USA where I work on the Cyber Innovations Lab mostly focusing on modern deep learning techniques on computer vision and multimodal systems.
                </p>
                <p>
                  At the lab, I am advised by <a href="https://sites.google.com/view/nickrahimi/home">Dr. Nick Rahimi</a> and closely work with him and his graduate and undergraduate students on topics like Stable Diffusion, Vision Transformers, Kolmogorov Arnold Networks, Cybersecurity, Visual Question Answering, NLP and Brain-Computer Interface. I was awarded <strong>$5500</strong> summer research grant in 2025 by the Drapeau Center for Undergraduate Research (DCUR) for my research on Gaussian Splatting.
                </p>
                <p>
                  I am also the Lead Organizer of the Google Developers Group (GDG) On Campus at USM where I also previously served as the Head of Artificial Intelligence at Google Developers Student Club at USM and represent the School of Computing Science and Computer Engineering's Ambassador as the Research Liason.
                </p>
                <p>
                  <strong><em>Non-Tech Trivia:</em> </strong>
                  I play bansuri and read literature. I also won the Eagles Write Award (best assignment among all freshmen) 2023/4 for an essay I wrote in 45 minutes.
                </p>
                <p style="text-align:center">
                  <a href="mailto:codeashim@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/AshimDahalResume.pdf">Resume</a> &nbsp;/&nbsp;
                  <a href="data/AshimDahalCV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/ashimdahal.txt">Bio</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=Nt9K4nsAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/ashimdahal/">Github</a>&nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/ashimdahal/">Linked In</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/AshimDahal.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/AshimDahal.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about understanding scene, analysing Deep Learning techniques, and inferring meaningful information by tinkering with model architectures and their loss function optimization. Some of my works in computer vision are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr onmouseout="r2r_stop()" onmouseover="r2r_start()" bgcolor="#ffffd0">
              <td style="padding:16px;width:20%;vertical-align:middle">
                  <img src='./images/qualitative_analysis.png' width=100%>
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <!--<a href="https://relight-to-reconstruct.github.io/">-->
                  <span class="papertitle">POVQA: Preference-Optimized Video Question Answering with Rationales for Data Efficiency</span>
                <!--</a>-->
                <br>
                <strong>Ashim Dahal</strong>, 
                <a>Ankit Ghimire</a>,
                <a href="https://murad-fawn.vercel.app/">Saydul Akbar Murad</a>,
                <a href="https://sites.google.com/view/nickrahimi/home">Nick Rahimi</a>
                <br>
                <em>arXiv</em>, 2025
                <br>
                <!-- <a href="https://github.com/ashimdahal/clip-shift-analysis">project page</a> -->
                <!-- / -->
                <a href="https://arxiv.org/abs/2510.01009">arXiv</a> | <<a href="https://povqa.pages.dev">project page</a>
                <p></p>
                <p>Making video question answering possible on large context scenes with minimal input tokens.</p>
              </td>
            </tr>

            <tr onmouseout="r2r_stop()" onmouseover="r2r_start()" bgcolor="#ffffd0">
              <td style="padding:16px;width:20%;vertical-align:middle">
                  <img src='./images/EMNLP_methodology.png' width=100%>
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <!--<a href="https://relight-to-reconstruct.github.io/">-->
                  <span class="papertitle">Redemption Score: An Evaluation Framework to Rank Image Captions While Redeeming Image Semantics and Language Pragmatics</span>
                <!--</a>-->
                <br>
                <strong>Ashim Dahal</strong>, 
                <a>Ankit Ghimire</a>,
                <a href="https://murad-fawn.vercel.app/">Saydul Akbar Murad</a>,
                <a href="https://sites.google.com/view/nickrahimi/home">Nick Rahimi</a>
                <br>
                <em>arXiv</em>, 2025
                <br>
                <!-- <a href="https://github.com/ashimdahal/clip-shift-analysis">project page</a> -->
                <!-- / -->
                <a href="https://arxiv.org/abs/2505.16180">arXiv</a>
                <p></p>
                <p>A robust framework to evaluate image-text pairs under perceptual, semantic, pragmatic and distributional alignment.</p>
              </td>
            </tr>

            <tr onmouseout="r2r_stop()" onmouseover="r2r_start()" >
              <td style="padding:16px;width:20%;vertical-align:middle">
                  <img src='./images/EEG methodology.png' width=100%>
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <!--<a href="https://relight-to-reconstruct.github.io/">-->
                  <span class="papertitle">EEG-to-Text Translation: A Model for Deciphering Human Brain Activity</span>
                <!--</a>-->
                <br>
                <a href="https://murad-fawn.vercel.app/">Saydul Akbar Murad</a>,
                <strong>Ashim Dahal</strong>, 
                <a href="https://sites.google.com/view/nickrahimi/home">Nick Rahimi</a>
                <br>
                <em>arXiv</em>, 2025
                <br>
                <!-- <a href="https://github.com/ashimdahal/clip-shift-analysis">project page</a> -->
                <!-- / -->
                <a href="https://arxiv.org/abs/2505.13936">arXiv</a>
                <p></p>
                <p> We propose a new model, R1 Translator, which aims to improve the performance of EEG-to-text decoding. </p>
              </td>
            </tr>

            <tr onmouseout="r2r_stop()" onmouseover="r2r_start()" bgcolor="#ffffd0">
              <td style="padding:16px;width:20%;vertical-align:middle">
                  <img src='./images/attention_maps_.jpeg' width=100%>
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <!--<a href="https://relight-to-reconstruct.github.io/">-->
                  <span class="papertitle">Embedding Shift Dissection on CLIP: Effects of Augmentations on VLM's Representation Learning</span>
                <!--</a>-->
                <br>
                <strong>Ashim Dahal</strong>, 
                <a href="https://murad-fawn.vercel.app/">Saydul Akbar Murad</a>,
                <a href="https://sites.google.com/view/nickrahimi/home">Nick Rahimi</a>
                <br>
                <em>MIV at <strong>CVPR</strong> (Proceedings Track)</em>, 2025
                <br>
                <a href="https://github.com/ashimdahal/clip-shift-analysis">project page</a>
                /
                <a href="https://arxiv.org/abs/2503.23495">arXiv</a>
                <p></p>
                <p>How exactly does the representation on ViT model like CLIP change when we apply different levels and kinds of augmentations to them? This short paper explains this very question.</p>
              </td>
            </tr>

            <tr onmouseout="r2r_stop()" onmouseover="r2r_start()" bgcolor="#ffffd0">
              <td style="padding:16px;width:20%;vertical-align:middle">
                  <img src='images/vitvcnn.png' width=100%>
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <!--<a href="https://relight-to-reconstruct.github.io/">-->
                  <span class="papertitle">Heuristical Comparison of Vision Transformers Against Convolutional Neural Networks for Semantic Segmentation on Remote Sensing Imagery</span>
                <!--</a>-->
                <br>
                <strong>Ashim Dahal</strong>, 
                <a href="https://murad-fawn.vercel.app/">Saydul Akbar Murad</a>,
                <a href="https://sites.google.com/view/nickrahimi/home">Nick Rahimi</a>
                <br>
                <em>IEEE Sensors Journal <strong> Impact Factor: 4.3</strong></em>, 2025
                <br>
                <a href="https://github.com/ashimdahal/ViT-vs-CNN-Image-Segmentation">project page</a>
                /
                <a href="https://arxiv.org/abs/2411.09101">arXiv</a>
                <p></p>
                <p> 
                  Analysis of Vision Transformers (ViT) against Convolutional Neural Networks (UNet CNN) for image segmentation on Remote Sensing iSAID dataset. We propose a novel loss function that helps a smaller CNN model to perform equally to a 5x larger ViT model.
                </p>
              </td>
            </tr>

            <tr >
              <td style="padding:16px;width:20%;vertical-align:middle">
                  <img src='./images/tweet-methodology.jpg' width=100%>
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <!--<a href="https://relight-to-reconstruct.github.io/">-->
                  <span class="papertitle">Multi-Lingual Cyber Threat Detection in Tweets/X Using ML, DL, and LLM: A Comparative Analysis</span>
                <!--</a>-->
                <br>
                <a href="https://murad-fawn.vercel.app/">Saydul Akbar Murad</a>,
                <strong>Ashim Dahal</strong>, 
                <a href="https://sites.google.com/view/nickrahimi/home">Nick Rahimi</a>
                <br>
                <em>arXiv</em>, 2025
                <br>
                <a href="https://relight-to-reconstruct.github.io/">project page</a>
                /
                <a href="https://arxiv.org/abs/2502.04346">arXiv</a>
                <p></p>
                <p>
                  Threats over X are given on multiple languages. This paper proposes a new dataset and methodology to detect cyber threats spread over tweets on X.
                </p>
              </td>
            </tr>

            <tr onmouseout="r2r_stop()" onmouseover="r2r_start()" bgcolor="#ffffd0">
              <td style="padding:16px;width:20%;vertical-align:middle">
                  <img src='images/ckan.png' width=100%>
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <!--<a href="https://relight-to-reconstruct.github.io/">-->
                  <span class="papertitle">Efficiency Bottlenecks of Convolutional Kolmogorov-Arnold Networks: A Comprehensive Scrutiny with ImageNet, AlexNet, LeNet and Tabular Classification</span>
                <!--</a>-->
                <br>
                <strong>Ashim Dahal</strong>, 
                <a href="https://murad-fawn.vercel.app/">Saydul Akbar Murad</a>,
                <a href="https://sites.google.com/view/nickrahimi/home">Nick Rahimi</a>
                <br>
                <em>arXiv</em>, 2025
                <br>
                <a href="https://github.com/ashimdahal/Study-of-Convolutional-Kolmogorov-Arnold-networks">project page</a>
                /
                <a href="https://arxiv.org/abs/2501.15757">arXiv</a>
                <p></p>
                <p> 
                  This paper analyzes Convolutional Kolmogorov Arnold Networks on ImageNet with Alexnet, MNIST with LeNet and Tabular CNN modification with MoA datasets.
                </p>
              </td>
            </tr>

            <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one"> 
                  <img src='images/xaicybersecurity.jpg' width=100%>
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <!--<a href="https://relight-to-reconstruct.github.io/">-->
                  <span class="papertitle">Analysis of Zero Day Attack Detection Using MLP and XAI</span>
                <!--</a>-->
                <br>
                <strong>Ashim Dahal</strong>, 
                <a href="https://www.linkedin.com/in/prabin-bajgai/">Prabin Bajgai</a>,
                <a href="https://sites.google.com/view/nickrahimi/home">Nick Rahimi</a>
                <br>
                <em>International Conference on Security and Management, Las Vegas</em>, 2024
                <br>
                <a href="https://github.com/ashimdahal/zero_day_ATTACK_detection">project page</a>
                /
                <a href="https://arxiv.org/abs/2501.16638">arXiv</a>
                <p></p>
                <p> 
                  Analysing zero day cyber attacks with MLP and SHAP. We use weighted loss function that changes the focus of the model into different parameters while learning thus leading to a model that doesn't overfit on majority class.
                </p>
              </td>
            </tr>

            <tr >
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one"> 
                  <img src='images/jelly.png' width=100%>
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <!--<a href="https://relight-to-reconstruct.github.io/">-->
                  <span class="papertitle">Effectiveness of Native Language for Conversational Bots</span>
                <!--</a>-->
                <br>
                <strong>Ashim Dahal</strong>, 
                <a href="https://anuj-khadka.com.np/">Anuj Khadka</a>,
                <a href="https://bishalkharal.com.np/">Bishal Kharal</a>,
                <a href="https://glocalteenhero.com/aashish-shah-an-enthusiastic-edu-technologist-2/">Aashish Shah</a>
                <br>
                <em>Europe PMC</em>, 2022
                <br>
                <a href="https://github.com/ashimdahal/jelly">project page</a>
                /
                <a href="https://europepmc.org/article/ppr/ppr561933">paper</a>
                <p></p>
                <p> 
                  We created "Jelly" the first Romanized Nepali Chatbot using facebook's BlenderBot and conducted a survey analysing the efficacy of natural language for mental health conversational bots.
                </p>
              </td>
            </tr>

            <tr  bgcolor="#ffffd0">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one"> 
                  <img src='images/docr.webp' width=100%>
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <!--<a href="https://relight-to-reconstruct.github.io/">-->
                  <span class="papertitle">Predicting Handwritten Devanagari Characters using modified-Lenet Model Architecture</span>
                <!--</a>-->
                <br>
                <strong>Ashim Dahal</strong>, 
                <a href="https://sushankattel.com.np">Sushan Kattel</a>
                <br>
                <em>Research Square</em>, 2022
                <br>
                <a href="https://www.researchsquare.com/article/rs-2137648/v1">paper</a>
                <p></p>
                <p> 
                  We fine tuned a LeNet style CNN architecture to do OCR on handwritten Devanagari characters. These characters tend to be more complicated to understand than roman numerals and alphabets. 
                </p>
              </td>
            </tr>

            <tr >
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one"> 
                  <img src='images/big_or_home.png' width=100%>
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <!--<a href="https://relight-to-reconstruct.github.io/">-->
                  <span class="papertitle">Do you “Go big or go home” with Neural Networks?</span>
                <!--</a>-->
                <br>
                <strong>Ashim Dahal</strong>
                <br>
                <em>Research Square</em>, 2022
                <br>
                <a href="https://github.com/ashimdahal/Chicken-Recipe-Generator.git">project page</a> / 
                <a href="https://www.researchsquare.com/article/rs-1716492/v2">paper</a>
                <p></p>
                <p> 
                  Used TensorFlow's guide on a self curated chicken recipe dataset to then create a GRU based RNN model which would generate new recipes. Did ablation study on data preprocessing and noted down the effects of different processing techniques on the final generator.
                </p>
              </td>
            </tr>

            <tr >
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one"> 
                  <img src='images/ownarobot.png' width=100%>
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <!--<a href="https://relight-to-reconstruct.github.io/">-->
                  <span class="papertitle">Would you own a ROBOT?: A detailed research on public response to the nooks and crannies of owning a robot.</span>
                <!--</a>-->
                <br>
                <strong>Ashim Dahal</strong>
                <br>
                <em>The Ninth National Conference on Science and Technology, Lalitpur, Nepal</em>, 2022
                <br>
                <a href="https://github.com/ashimdahal/Chicken-Recipe-Generator.git">project page</a> / 
                <a href="https://www.researchsquare.com/article/rs-1716492/v2">paper</a>
                <p></p>
                <p>
                  Surveyed 300+ individuals regarding the various implications of living on a robot-centric economy. Questions cover topics including privacy, jobs, requirements and feature required for robots to be mainstream or house-help machines.
                </p>
              </td>
            </tr>


          </tbody></table>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellaneous</h2>
              </td>
            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #fcb97d;">
								 <h2>Blogs and Paper Summaries</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://www.linkedin.com/in/ashimdahal/recent-activity/documents/">Linked In Paper Reviews: Currently Maintained</a>
                <br>
                <a href="https://ashimdahal.blogspot.com/">Blogs and Newsletters: I used to maintain back in 2020-2022</a>
              </td>
            </tr>


            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #aaba9e;">
								 <h2 id = "bootcamps">Teaching in Bootcamps</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://github.com/drcfsorg/Pokhara_ML_Bootcamp">7 Days Pokhara Machine Learning Bootcamp, 2023</a>
								<br>
                <a href="https://github.com/drcfsorg/DRCFS_Pokhara_Pragati_python_bootcamp">7 Days Bootcamp on Pragati School, 2023</a>
								<br>
                <a href="https://github.com/drcfsorg/DRCFS_Chitwan_ML_Bootcamp">DRCFS Chitwan Bootcamp, 2023</a>
								<br>
								<a href="https://github.com/twlorg/TWL_DRCFS_March_Madness_Python_Bootcamp.git">14 Days Intermediate Python Bootcamp, 2023</a>
								<br>
								<a href="https://github.com/drcfsorg/TWL_DRCFS_30DaysPythonBootcamp">30 Days Beginner Python Bootcamp, 2022</a>
              </td>
            </tr>

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Invited Talks</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://drive.google.com/drive/folders/1XbNqKAd2IPio04lJBkGnd2IRLty0D_qs?usp=drive_link">What is an Image?, USM, Hattiesburg, MS, USA, 2025</a>
                <br>
                <a href="https://drive.google.com/drive/folders/1VIhtODWWRqT1hE59YT1bMDc6y36qDZ0v?usp=drive_link">Using AI in journalism, Federation of Nepali Journalist, Kaski Nepal</a>
                <br>
                <a href="https://drive.google.com/drive/folders/11qVf7YNRLIbWpecbFYKqffVXtti3Ffwt?usp=drive_link">Future of AI, Fishtail Academy, Pokhara, Nepal</a>
                <br>
              </td>
            </tr>
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
                <div class="colored-box" style="background-color: #edd892;">
                  <h2>Teaching in Academia</h2>
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://drive.google.com/drive/folders/1BcmIjQz4sU8pHxlHMQ7ax67HvQMqyRNo?usp=sharing">Durbar High School: Robotics Instructor</a>
                <br>
              </td>
            </tr>
          </tbody></table>
								  
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
								    <tr>
								      <td style="padding:0px">
								        <br>
								        <p style="text-align:center;font-size:small;">
								          This website is adapted from: <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>. 
								        </p>
								      </td>
								    </tr>
          
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
